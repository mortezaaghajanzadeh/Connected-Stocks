{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vv4(row):\n",
    "    row = str(row)\n",
    "    X = [1,1,1]\n",
    "    X[0] = row[0:4]\n",
    "    X[1] = row[4:6]\n",
    "    X[2] = row[6:8]\n",
    "    return X[0]+'-'+X[1]+'-'+X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vv(row):\n",
    "    X = row.split('-')\n",
    "    return X[0]+X[1]+X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DriveYearMonthDay(d):\n",
    "    d['jalaliDate'] = d['jalaliDate'].astype(str)\n",
    "    d['Year'] = d['jalaliDate'].str[0:4]\n",
    "    d['Month'] = d['jalaliDate'].str[4:6]\n",
    "    d['Day'] = d['jalaliDate'].str[6:8]\n",
    "    d['jalaliDate'] = d['jalaliDate'].astype(int)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"H:\\Economics\\Finance(Prof.Heidari-Aghajanzadeh)\\Data\"\n",
    "n = path + '\\Cleaned_Stocks_Holders_1399-07-21_From96.csv'\n",
    "df = pd.read_csv(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(df.loc[df['Holder']=='شخص حقیقی'].index)\n",
    "df = df.drop(df[(df['Trade']=='No')&((df['close_price']==10)|(df['close_price']==1000)|(df['close_price']==10000)|(df['close_price']==100000))].index)\n",
    "df = df.drop(df[(df['symbol'] == 'وقوام')&(df['close_price'] == 1000)].index)\n",
    "symbols = [ 'سپرده','هما','وهنر-پذیره','نکالا','تکالا','اکالا','توسعه گردشگری ','وآفر','ودانا','نشار','نبورس','چبسپا','بدکو','چکارم','تراک','کباده','فبستم','تولیددارو','قیستو','خلیبل','پشاهن','قاروم','هوایی سامان','کورز','شلیا','دتهران','نگین','کایتا','غیوان','تفیرو','سپرمی','بتک']\n",
    "df = df.drop(df[df['symbol'].isin(symbols)].index)\n",
    "df = df.drop(df[(df.symbol == 'اتکای')&(df.close_price == 1000)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HolderData = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"H:\\Economics\\Finance(Prof.Heidari-Aghajanzadeh)\\Data\"\n",
    "n1 = path + '\\Stocks_Prices_1399-07-20' + '.csv'\n",
    "df1 = pd.read_csv(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['jalaliDate'] = df1['jalaliDate'].apply(vv)\n",
    "df = df1\n",
    "symbols = [ 'سپرده','هما','وهنر-پذيره','نکالا','تکالا','اکالا','توسعه گردشگری ','وآفر','ودانا','نشار','نبورس','چبسپا','بدکو','چکارم','تراک','کباده','فبستم','تولیددارو','قیستو','خلیبل','پشاهن','قاروم','هوایی سامان','کورز','شلیا','دتهران','نگین','کایتا','غیوان','تفیرو','سپرمی','بتک']\n",
    "df = df.drop(df[df['name'].isin(symbols)].index)\n",
    "df = df.drop(df[df.group_name== 'صندوق سرمایه گذاری قابل معامله'].index)\n",
    "df = df.drop(df[(df.name == 'اتکای')&(df.close_price == 1000)].index)\n",
    "df = df.drop_duplicates()\n",
    "df = df.drop(df.loc[(df['volume'] == 0)].index).sort_values(by =['name','jalaliDate']).drop(columns = ['volume','quantity']).rename(columns = {'name':'symbol'})\n",
    "df = DriveYearMonthDay(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PriceData = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PriceData.jalaliDate.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'\n",
    "df2 = pd.read_csv(n2)\n",
    "df2 = df2[['symbol', 'year','total_assets']].rename(columns = {\"year\":'Year',\"total_assets\":'BookValue'})\n",
    "df2['Year'] = df2['Year'].astype(str)\n",
    "PriceData = PriceData.merge(df2,on=['symbol','Year']).drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PriceData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(WeeklyHolderData.symbol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WinLos = PriceData[['jalaliDate', 'date', 'symbol','close_price']]\n",
    "WinLos['date1'] = WinLos['date'].apply(vv4)\n",
    "WinLos['date1'] = pd.to_datetime(WinLos['date1']) \n",
    "WinLos['week_of_year'] = WinLos['date1'].dt.week \n",
    "WinLos['year_of_year'] = WinLos['date1'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekRet(g):\n",
    "    g['weekRet'] = (g.close_price.iloc[-1] - g.close_price.iloc[0])/g.close_price.iloc[0] * 100\n",
    "    return g\n",
    "\n",
    "gg = WinLos.groupby(['symbol', 'year_of_year','week_of_year'])\n",
    "d = gg.apply(weekRet)\n",
    "#Don't Delete this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearRet(g):\n",
    "    f = g.groupby(['year_of_year']).last().reset_index()\n",
    "    f['yearRet'] = f['close_price'].pct_change(periods = 1)*100\n",
    "    f = f[['year_of_year','symbol','week_of_year','yearRet']]\n",
    "    g = g.merge(f,on = ['year_of_year','symbol','week_of_year'])\n",
    "    return g\n",
    "\n",
    "gg = d.groupby(['symbol', 'week_of_year'])\n",
    "d2 = gg.apply(yearRet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WinLosData = d2.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WinLosData = WinLosData.groupby(['symbol','year_of_year','week_of_year']).last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WinLosData = WinLosData[WinLosData.jalaliDate > 13960000].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WinLosData = WinLosData.groupby(['year_of_year','week_of_year']).apply(lambda x: x.sort_values([\"yearRet\"], ascending = False)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def WinLos(g):\n",
    "    Winner = g.loc[g['yearRet'] >= g['yearRet'].quantile(0.9)]['yearRet'].mean()\n",
    "    Loser = g.loc[g['yearRet'] <= g['yearRet'].quantile(0.1)]['yearRet'].mean()\n",
    "    g['Winner_Loser'] = Winner - Loser\n",
    "    g = g[['year_of_year','week_of_year','Winner_Loser']].drop_duplicates()\n",
    "    return g\n",
    "\n",
    "WL = WinLosData.groupby(['year_of_year','week_of_year'])\n",
    "WinLosData = WL.apply(WinLos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WinLosData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WinLosData = WinLosData.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PriceData.jalaliDate.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WinLosData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrout = HolderData[['symbol','shrout','date','jalaliDate']].drop_duplicates()\n",
    "PriceData = PriceData.merge(shrout,on = ['symbol','date','jalaliDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PriceData['date1'] = PriceData['date'].apply(vv4)\n",
    "PriceData['date1'] = pd.to_datetime(PriceData['date1']) \n",
    "PriceData['week_of_year'] = PriceData['date1'].dt.week \n",
    "PriceData['year_of_year'] = PriceData['date1'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapingdict = dict(zip(zip(list(WinLosData.year_of_year),list(WinLosData.week_of_year)),list(WinLosData.Winner_Loser)))\n",
    "PriceData['Winner_Loser'] = PriceData.set_index(['year_of_year','week_of_year']).index.map(mapingdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PriceData = PriceData[['jalaliDate', 'date', 'symbol','group_name','close_price','BookValue', 'shrout','week_of_year', 'year_of_year','Winner_Loser']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PriceData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = r\"G:\\TseClient\\Data adjusted\"\n",
    "index = pd.read_excel(path2 + '\\IRX6XTPI0009.xls')[['<COL14>','<CLOSE>']].rename(columns = {'<COL14>':'jalaliDate','<CLOSE>':'Index'})\n",
    "index['Market_return'] =  index['Index'].pct_change(periods = 1)*100\n",
    "# index = index.drop(columns = ['Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PriceData = PriceData.merge(index,on = ['jalaliDate']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = d.drop(columns = ['close_price','date1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeekPriceData = PriceData.groupby(['symbol','year_of_year','week_of_year']).last().reset_index()\n",
    "WeekPriceData = WeekPriceData.merge(d,on = ['symbol','year_of_year','week_of_year','jalaliDate','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeekPriceData['MarketCap']= WeekPriceData['close_price'] * WeekPriceData['shrout']/1e5\n",
    "WeekPriceData['MarketCap'] = WeekPriceData['MarketCap'].astype(int)\n",
    "WeekPriceData['BookToMarket'] = WeekPriceData['BookValue']/WeekPriceData['MarketCap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Index = PriceData[['week_of_year','year_of_year','Winner_Loser','Index','Market_return']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weekRet(g):\n",
    "    g['MarketweekRet'] = (g.Index.iloc[-1] - g.Index.iloc[0])/g.Index.iloc[0] * 100\n",
    "    return g\n",
    "\n",
    "gg = Index.groupby(['year_of_year','week_of_year'])\n",
    "WeekIndex = gg.apply(weekRet)\n",
    "#Don't Delete this cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WeekIndex = \n",
    "WeekIndex = WeekIndex.groupby(['year_of_year','week_of_year']).last().reset_index()[['year_of_year','week_of_year','MarketweekRet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeekIndex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMB(g):\n",
    "    Large = g.loc[g['MarketCap'] >= g['MarketCap'].quantile(0.9)]['weekRet'].mean()\n",
    "    Small = g.loc[g['MarketCap'] <= g['MarketCap'].quantile(0.1)]['weekRet'].mean()\n",
    "    Value = g.loc[g['BookToMarket'] >= g['BookToMarket'].quantile(0.9)]['weekRet'].mean()\n",
    "    Growth = g.loc[g['BookToMarket'] <= g['BookToMarket'].quantile(0.1)]['weekRet'].mean()\n",
    "    \n",
    "    g['SMB'] = Small - Large\n",
    "    g['HML'] = Value - Growth\n",
    "    \n",
    "    g = g[['year_of_year','week_of_year','SMB','HML','Winner_Loser']].drop_duplicates(['year_of_year','week_of_year'])\n",
    "    return g\n",
    "\n",
    "WL = WeekPriceData.groupby(['year_of_year','week_of_year'])\n",
    "Factors = WL.apply(SMB)\n",
    "Factors = Factors.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapingdict = dict(zip(zip(list(WeekIndex.year_of_year),list(WeekIndex.week_of_year)),list(WeekIndex['MarketweekRet'])))\n",
    "Factors['MarketweekRet'] = Factors.set_index(['year_of_year','week_of_year']).index.map(mapingdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Factors.to_excel(path + '\\Analyzed Data'+'\\Factors.xlsx',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Factors = pd.read_excel(path + '\\Analyzed Data'+'\\Factors.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HolderData\n",
    "HolderData['date1'] = HolderData['date'].apply(vv4)\n",
    "HolderData['date1'] = pd.to_datetime(HolderData['date1']) \n",
    "HolderData['week_of_year'] = HolderData['date1'].dt.week \n",
    "HolderData['Month_of_year'] = HolderData['date1'].dt.month \n",
    "HolderData['year_of_year'] = HolderData['date1'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldates = HolderData.groupby(['symbol','year_of_year','Month_of_year','week_of_year']).last()\n",
    "ldates = ldates.reset_index()[['symbol','date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fkey = zip(list(ldates.symbol),list(ldates.date))\n",
    "mapingdict = dict(zip(fkey,[1]*(len(ldates.symbol)+1)))\n",
    "HolderData['Last'] = HolderData.set_index(['symbol','date']).index.map(mapingdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeeklyHolderData = HolderData.loc[HolderData.Last == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ['SMB','HML','Winner_Loser','MarketweekRet']: \n",
    "    print(t)\n",
    "    mapingdict = dict(zip(zip(list(Factors.year_of_year),list(Factors.week_of_year)),list(Factors[t])))\n",
    "    WeeklyHolderData[t] = WeeklyHolderData.set_index(['year_of_year','week_of_year']).index.map(mapingdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fkey = zip(list(d.symbol),list(d.date))\n",
    "mapingdict = dict(zip(fkey,d.weekRet))\n",
    "WeeklyHolderData['weekRet'] = WeeklyHolderData.set_index(['symbol','date']).index.map(mapingdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WeekPriceData = WeeklyHolderData.groupby(['symbol','year_of_year','Month_of_year','week_of_year']).last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeekPriceData = WeekPriceData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WeekPriceData.groupby(['symbol'])\n",
    "g = wg.get_group('آ س پ')\n",
    "g\n",
    "# y = 'weekRet'\n",
    "# x = ['MarketweekRet','HML','SMB','Winner_Loser']\n",
    "# model = sm.OLS(g[y], sm.add_constant(g[x])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WeekPriceData.groupby(['symbol'])\n",
    "def FourFactor(g):\n",
    "    try:\n",
    "        y = 'weekRet'\n",
    "        x = ['MarketweekRet','HML','SMB','Winner_Loser']\n",
    "        model = sm.OLS(g[y], sm.add_constant(g[x])).fit()\n",
    "        g['4-Residual'] = g ['weekRet'] - (model.params[0] + model.params[1]*g['MarketweekRet'] + model.params[2]*g['HML']  + model.params[3]*g['SMB']  + model.params[4]*g['Winner_Loser']) \n",
    "    except:\n",
    "        print(g.symbol.iloc[0])\n",
    "        g = pd.DataFrame()\n",
    "    return g\n",
    "\n",
    "def ThreeFactor(g):\n",
    "    try:\n",
    "        y = 'weekRet'\n",
    "        x = ['MarketweekRet','HML','SMB']\n",
    "        model = sm.OLS(g[y], sm.add_constant(g[x])).fit()\n",
    "        g['3-Residual'] = g ['weekRet'] - (model.params[0] + model.params[1]*g['MarketweekRet'] + model.params[2]*g['HML']  + model.params[3]*g['SMB'] ) \n",
    "    except:\n",
    "        print(g.symbol.iloc[0])\n",
    "        g = pd.DataFrame()\n",
    "    return g\n",
    "re = wg.apply(FourFactor)\n",
    "re2 = wg.apply(ThreeFactor)\n",
    "re['3-Residual'] = re2['3-Residual']\n",
    "re = re.reset_index(drop=True).drop(columns = ['group_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = HolderData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df.Trade == 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date1'] = df['date'].apply(vv4)\n",
    "df['date1'] = pd.to_datetime(df['date1']) \n",
    "df['week_of_year'] = df['date1'].dt.week \n",
    "df['year_of_year'] = df['date1'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(re,on=['symbol', 'year_of_year', 'week_of_year', 'jalaliDate', 'date','close_price','shrout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Holders = list(set(df.Holder))\n",
    "Holders.sort()\n",
    "ids = list(range(len(Holders)))\n",
    "mapingdict = dict(zip(Holders, ids))\n",
    "df['Holder_id'] = df['Holder'].map(mapingdict)\n",
    "\n",
    "symbols = list(set(df.symbol))\n",
    "symbols.sort()\n",
    "ids = list(range(len(symbols)))\n",
    "mapingdict = dict(zip(symbols, ids))\n",
    "df['id'] = df['symbol'].map(mapingdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month_of_year'] = df['date1'].dt.month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata = df.groupby(['id'])\n",
    "g = gdata.get_group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "gg = df.groupby(['id'])\n",
    "\n",
    "def FCAPf(S_g,g):\n",
    "    intersection = list(set.intersection(set(S_g.date), set(g.date)))\n",
    "    g = g.loc[g.date.isin(intersection)]\n",
    "    S_g = S_g.loc[S_g.date.isin(intersection)]\n",
    "    a = g.merge(S_g , on = ['Holder_id','date'])\n",
    "    if len(a) == 0: \n",
    "        return\n",
    "    else:\n",
    "        intersection = list(set.intersection(set(S_g.date), set(g.date)))\n",
    "        g = g.loc[g.date.isin(intersection)]\n",
    "        S_g = S_g.loc[S_g.date.isin(intersection)]\n",
    "        a = g.merge(S_g , on = ['Holder_id','date','jalaliDate','week_of_year','month_of_year','year_of_year'])\n",
    "        a['FCAPf'] = (a['nshares_x']*a['close_price_x'] + a['nshares_y']*a['close_price_y'])/(a['shrout_x']*a['close_price_x'] + a['shrout_y']*a['close_price_y'])\n",
    "        a['SizeRatio'] = (a['MarketCap_x'])/(a['MarketCap_y'])\n",
    "\n",
    "        f = a.groupby(['date','jalaliDate','id_x','id_y','week_of_year','month_of_year','year_of_year','group_name_x','group_name_y','weekRet_x','weekRet_y','SizeRatio','BookToMarket_x','BookToMarket_y','MarketCap_x','MarketCap_y','4-Residual_x','4-Residual_y','3-Residual_x','3-Residual_y'])['FCAPf'].sum().to_frame().reset_index()\n",
    "        fc = f.groupby(['year_of_year','month_of_year'])[['4-Residual_x','4-Residual_y','3-Residual_x','3-Residual_y']].corr().reset_index()\n",
    "        FourCor = fc.loc[fc.level_2 == '4-Residual_y'][['year_of_year','month_of_year','4-Residual_x']].rename(columns = {'4-Residual_x':'ρ_4'})\n",
    "        ThreeCor = fc.loc[fc.level_2 == '3-Residual_y'][['year_of_year','month_of_year','3-Residual_x']].rename(columns = {'3-Residual_x':'ρ_3'})\n",
    "        TimeId = zip(list(FourCor.year_of_year),list(FourCor.month_of_year))\n",
    "        mapingdict = dict(zip(TimeId,list(FourCor.ρ_4)))\n",
    "        f['ρ_4'] = f.set_index(['year_of_year','month_of_year']).index.map(mapingdict)\n",
    "        TimeId = zip(list(ThreeCor.year_of_year),list(ThreeCor.month_of_year))\n",
    "        mapingdict = dict(zip(TimeId,list(ThreeCor.ρ_3)))\n",
    "        f['ρ_3'] = f.set_index(['year_of_year','month_of_year']).index.map(mapingdict)  \n",
    "        f['FCAPF'] = (f['FCAPf'] - f['FCAPf'].mean()).divide(f['FCAPf'].std())\n",
    "        return f\n",
    "\n",
    "for i in gdata.groups.keys():\n",
    "    g = gdata.get_group(i)\n",
    "    F_id = g.id.iloc[0]\n",
    "    print(F_id)\n",
    "    Next_df = df[df.id > F_id]\n",
    "    S_gg = Next_df.groupby(['id'])\n",
    "    data = data.append(S_gg.apply(FCAPf , g = g ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.reset_index(drop = True).drop_duplicates(['id_x','id_y','month_of_year','year_of_year']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "symbols = list(set(df.symbol))\n",
    "symbols.sort()\n",
    "ids = list(range(len(symbols)))\n",
    "mapingdict = dict(zip(ids,symbols))\n",
    "d['symbol_x'] = d['id_x'].map(mapingdict)\n",
    "d['symbol_y'] = d['id_y'].map(mapingdict)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['month_of_year'] = d['month_of_year'].astype(str)\n",
    "def add(row):\n",
    "    if len(row)<2:\n",
    "        row = '0'+ row\n",
    "    return row\n",
    "\n",
    "d['month_of_year'] = d['month_of_year'].apply(add )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d['year_of_year'] = d['year_of_year'].astype(str)\n",
    "\n",
    "d['Year_Month'] = d['year_of_year'] + d['month_of_year']\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = list(set(d.Year_Month))\n",
    "days.sort()\n",
    "t = list(range(len(days)))\n",
    "mapingdict = dict(zip(days, t))\n",
    "d['t'] = d['Year_Month'].map(mapingdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['id_x'] = d['id_x'].astype(str)\n",
    "d['id_y'] = d['id_y'].astype(str)\n",
    "d['id'] = d['symbol_x'] + d['symbol_y']\n",
    "ids = list(set(d.id))\n",
    "ids.sort()\n",
    "id = list(range(len(ids)))\n",
    "mapingdict = dict(zip(ids, id))\n",
    "d['id'] = d['id'].map(mapingdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d['size1'] = 0\n",
    "d.loc[d.MarketCap_x>d.MarketCap_y,'size1'] = d[d.MarketCap_x>d.MarketCap_y]['MarketCap_x']\n",
    "d.loc[d.MarketCap_x<d.MarketCap_y,'size1'] = d[d.MarketCap_x<d.MarketCap_y]['MarketCap_y']\n",
    "d['size2'] = 0\n",
    "d.loc[d.MarketCap_x>d.MarketCap_y,'size2'] = d[d.MarketCap_x>d.MarketCap_y]['MarketCap_y']\n",
    "d.loc[d.MarketCap_x<d.MarketCap_y,'size2'] = d[d.MarketCap_x<d.MarketCap_y]['MarketCap_x']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['ρ3_f'] = d.groupby(['id'])['ρ_3'].shift(-1)\n",
    "d['ρ4_f'] = d.groupby(['id'])['ρ_4'].shift(-1)\n",
    "d['ρ3_f2'] = d.groupby(['id'])['ρ_3'].shift(-2)\n",
    "d['ρ4_f2'] = d.groupby(['id'])['ρ_4'].shift(-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d['SameSize'] = d['size1'] - d['size2']\n",
    "d['SameSize'] = (d['SameSize']-d['SameSize'].mean()).divide(d['SameSize'].std())\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['sgroup'] = 0\n",
    "d.loc[d.group_name_x == d.group_name_y,'sgroup'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n3 = path + '\\\\NormalzedFCAP2.csv'\n",
    "d.to_csv(n3,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[d.id == 4006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[d.duplicated(['t','id'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
