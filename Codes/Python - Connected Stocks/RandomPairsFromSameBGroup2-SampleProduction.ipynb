{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"H:\\Economics\\Finance(Prof.Heidari-Aghajanzadeh)\\Data\\Connected stocks\\\\\"\n",
    "path = r\"C:\\Users\\RA\\Desktop\\RA_Aghajanzadeh\\Data\\\\\"\n",
    "# df = pd.read_csv(path + 'Holder_Residual.csv')\n",
    "# n3 = path + 'NormalzedFCAP5.1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def RPair(g,Pairs,dgg,timeId,GData):\n",
    "        if len(g) == 0:\n",
    "            return\n",
    "        print(g.name, end=\"\\r\", flush=True) \n",
    "        x = pd.DataFrame()\n",
    "        RP = x\n",
    "        \n",
    "        CFactor = g[['t','FCAPf','FCA','MonthlyFCAPf', 'MonthlyFCA','WeeklyFCAPf',\n",
    "                    'WeeklyFCA','FCAP*', 'FCA*', 'WeeklyFCAP*', 'WeeklyFCA*', \n",
    "                    'MonthlyFCAP*','MonthlyFCA*','Holder_act','sBgroup']]\n",
    "        flag = 0\n",
    "        j = 1\n",
    "        dg = x\n",
    "        S_g = x\n",
    "        while flag == 0 and j < 100:\n",
    "            nid_x , nid_y = randomId(g,GData,Pairs)\n",
    "            if nid_x == \"n\":\n",
    "                j += 1\n",
    "                continue\n",
    "            dg = dgg.get_group(nid_x)\n",
    "            S_g = dgg.get_group(nid_y)\n",
    "            dg = dg.loc[dg.date.isin(g.date)]\n",
    "            S_g = S_g.loc[S_g.date.isin(g.date)]\n",
    "#             print(j , len(dg),len(S_g))\n",
    "            if  len(dg) >= 0.5*len(g) and len(S_g) >= 0.5*len(g):\n",
    "                flag = 1\n",
    "            j += 1\n",
    "            \n",
    "                \n",
    "        if len(dg) < 0.5*len(g) or len(S_g) < 0.5*len(g) :\n",
    "            return RP\n",
    "        \n",
    "        RP = RFCAPf(S_g,dg) \n",
    "        RP = RP.merge(timeId,on = 'date')\n",
    "        RP = RP.merge(CFactor,on = 't')\n",
    "        RP['nId'] = str(g.name)\n",
    "        \n",
    "        return RP\n",
    "    \n",
    "    def randomId(g,GData,Pairs):\n",
    "        Gx = set(GData[(GData.BGId == g.BGId_x.iloc[0])&(GData.id != g.id_y.iloc[0])].id)\n",
    "        id_x = g.id_x.iloc[0]\n",
    "        P_x = set(Pairs[Pairs.id_x == id_x].id_y)\n",
    "        P_x.update(Pairs[Pairs.id_y == id_x].id_x)\n",
    "        P_x = Gx.difference(P_x)\n",
    "        P_x = list(P_x)\n",
    "        \n",
    "        Gy = set(GData[(GData.BGId == g.BGId_y.iloc[0])&(GData.id != g.id_x.iloc[0])].id)\n",
    "        id_y = g.id_y.iloc[0]\n",
    "        P_y = set(Pairs[Pairs.id_x == id_y].id_y)\n",
    "        P_y.update(Pairs[Pairs.id_y == id_y].id_x)\n",
    "        P_y = Gy.difference(P_y)\n",
    "        P_y = list(P_y)\n",
    "        \n",
    "        round = max(len(P_x),len(P_y))\n",
    "        \n",
    "        flag = 0 \n",
    "        j = 0\n",
    "        while flag == 0 and j< round:\n",
    "            nid_x = P_x[random.randint(0, len(P_x)-1)]\n",
    "            nid_y = P_y[random.randint(0, len(P_y)-1)]\n",
    "            ns = set(Pairs[Pairs.id_x == nid_x].id_y)\n",
    "            ns.update(Pairs[Pairs.id_y == nid_x].id_x)\n",
    "            if nid_y not in ns:\n",
    "                flag = 1\n",
    "            \n",
    "            j = j + 1\n",
    "            if flag == 0 and j>= round:\n",
    "                nid_x , nid_y = 'n','n'\n",
    "        \n",
    "        return nid_x , nid_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def RFCAPf(S_g,g):\n",
    "        f= RCalculation(g,S_g)\n",
    "        if len (f) == 0:\n",
    "            return f\n",
    "        f = MonthlyCalculation(f)  \n",
    "        return f\n",
    "\n",
    "    def RCalculation(g,S_g):\n",
    "        intersection = list(set.intersection(set(S_g.date), set(g.date)))\n",
    "        g = g.loc[g.date.isin(intersection)].drop(columns = ['Holder', 'nshares', 'type', 'Percent',\n",
    "                                                             'Number_Change', 'Percent_Change', 'Condition', 'Trade'])\n",
    "        S_g = S_g.loc[S_g.date.isin(intersection)].drop(columns = ['Holder', 'nshares', 'type', 'Percent',\n",
    "                                                             'Number_Change', 'Percent_Change', 'Condition', 'Trade'])\n",
    "        \n",
    "        a = g.merge(S_g , on = ['date','jalaliDate','week_of_year',\n",
    "                                'month_of_year','year_of_year'])\n",
    "\n",
    "        a['SizeRatio'] = (a['MarketCap_x'])/(a['MarketCap_y'])\n",
    "        f = a\n",
    "        f['size1'] = 0\n",
    "        f.loc[f.MarketCap_x>f.MarketCap_y,'size1'] = f[f.MarketCap_x>f.MarketCap_y]['Percentile_Rank_x']\n",
    "        f.loc[f.MarketCap_x<f.MarketCap_y,'size1'] = f[f.MarketCap_x<f.MarketCap_y]['Percentile_Rank_y']\n",
    "        f['size2'] = 0\n",
    "        f.loc[f.MarketCap_x>f.MarketCap_y,'size2'] = f[f.MarketCap_x>f.MarketCap_y]['Percentile_Rank_y']\n",
    "        f.loc[f.MarketCap_x<f.MarketCap_y,'size2'] = f[f.MarketCap_x<f.MarketCap_y]['Percentile_Rank_x']\n",
    "        f['SameSize'] =  f['size2'] -f['size1']\n",
    "        f['sgroup'] = 0\n",
    "        f.loc[f.group_name_x == f.group_name_y,'sgroup'] = 1\n",
    "        f.loc[f.group_name_x == f.group_name_y,'sgroup'] = 1\n",
    "        f['B/M1'] = 0\n",
    "        f.loc[f.MarketCap_x>f.MarketCap_y,'B/M1'] = f[f.MarketCap_x>f.MarketCap_y]['BookToMarket_x']\n",
    "        f.loc[f.MarketCap_x<f.MarketCap_y,'B/M1'] = f[f.MarketCap_x<f.MarketCap_y]['BookToMarket_y']\n",
    "        f['B/M2'] = 0\n",
    "        f.loc[f.MarketCap_x>f.MarketCap_y,'B/M2'] = f[f.MarketCap_x>f.MarketCap_y]['BookToMarket_y']\n",
    "        f.loc[f.MarketCap_x<f.MarketCap_y,'B/M2'] = f[f.MarketCap_x<f.MarketCap_y]['BookToMarket_x']\n",
    "        f['SameB/M'] = -1 * abs(f['B/M2'] -f['B/M1'])\n",
    "        \n",
    "        return f\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonthlyCalculation(f):\n",
    "\n",
    "    f = MonthlyCorr(f)        \n",
    "    \n",
    "    ff = f.groupby(['year_of_year','month_of_year'])[['SizeRatio','MarketCap_x',\n",
    "                                                      'MarketCap_y','Percentile_Rank_x',\n",
    "                                                   'Percentile_Rank_y','size1','size2',\n",
    "                                                      'SameSize','B/M1','B/M2','SameB/M']].mean().reset_index()\n",
    "    \n",
    "    vlist = ['SizeRatio', 'MarketCap_x','MarketCap_y', 'Percentile_Rank_x', 'Percentile_Rank_y', 'size1',\n",
    "           'size2', 'SameSize','B/M1','B/M2','SameB/M']\n",
    "    \n",
    "    for i in vlist:\n",
    "        TimeId = zip(list(ff.year_of_year),list(ff.month_of_year))\n",
    "        mapingdict = dict(zip(TimeId,list(ff[i])))\n",
    "        f['Monthly'+i] = f.set_index(['year_of_year','month_of_year']).index.map(mapingdict)\n",
    "    \n",
    "\n",
    "            \n",
    "    f['Monthlyρ_2_f'] = f['Monthlyρ_2'].shift(-1)\n",
    "    f['Monthlyρ_4_f'] = f['Monthlyρ_4'].shift(-1)\n",
    "    f['Monthlyρ_5_f'] = f['Monthlyρ_5'].shift(-1)\n",
    "    return f\n",
    "def MonthlyCorr(f):\n",
    "    \n",
    "    fc = f.groupby(['year_of_year','month_of_year'])[['2-Residual_x','2-Residual_y',\n",
    "                                                      '4_Residual_x','4_Residual_y',\n",
    "                                                      '5-Residual_x','5-Residual_y']].corr().reset_index()\n",
    "    \n",
    "    TwoCor = fc.loc[fc.level_2 == '2-Residual_y'][['year_of_year','month_of_year',\n",
    "                                                   '2-Residual_x']].rename(columns = {'2-Residual_x':'ρ_2'})\n",
    "    FourCor = fc.loc[fc.level_2 == '4_Residual_y'][['year_of_year','month_of_year',\n",
    "                                                    '4_Residual_x']].rename(columns = {'4_Residual_x':'ρ_4'})\n",
    "    ThreeCor = fc.loc[fc.level_2 == '5-Residual_y'][['year_of_year','month_of_year',\n",
    "                                                     '5-Residual_x']].rename(columns = {'5-Residual_x':'ρ_5'})\n",
    "    \n",
    "    TimeId = zip(list(TwoCor.year_of_year),list(TwoCor.month_of_year))\n",
    "    mapingdict = dict(zip(TimeId,list(TwoCor.ρ_2)))\n",
    "    f['Monthlyρ_2'] = f.set_index(['year_of_year','month_of_year']).index.map(mapingdict)\n",
    "    \n",
    "    TimeId = zip(list(FourCor.year_of_year),list(FourCor.month_of_year))\n",
    "    mapingdict = dict(zip(TimeId,list(FourCor.ρ_4)))\n",
    "    f['Monthlyρ_4'] = f.set_index(['year_of_year','month_of_year']).index.map(mapingdict)\n",
    "    \n",
    "    TimeId = zip(list(ThreeCor.year_of_year),list(ThreeCor.month_of_year))\n",
    "    mapingdict = dict(zip(TimeId,list(ThreeCor.ρ_5)))\n",
    "    f['Monthlyρ_5'] = f.set_index(['year_of_year','month_of_year']).index.map(mapingdict) \n",
    "    return f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(path + 'Holder_Residual.parquet')\n",
    "df = df[df.jalaliDate<13990000]\n",
    "# df = df.rename(columns = {'4_Residual':'4-Residual'})\n",
    "df.loc[df.week_of_year%2 == 1,'week_of_year'] = df.loc[df.week_of_year%2 == 1]['week_of_year']-1\n",
    "df = df.drop_duplicates(['date','symbol'])\n",
    "dgg = df.groupby(['id'])\n",
    "SId = pd.read_csv(path + \"SId\" + \".csv\")\n",
    "GData = pd.read_csv(path + \"GData\" + \".csv\")\n",
    "Pairs = pd.read_csv(path + \"Pairs\" + \".csv\")\n",
    "timeId = pd.read_csv(path + \"timeId\" + \".csv\")\n",
    "BG = df[['id','BGId']].drop_duplicates().reset_index(drop = True)\n",
    "m=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = path + \"NormalzedFCAP6.1\" + \".parquet\"\n",
    "a = pd.read_parquet(n)\n",
    "# a = a.rename(columns = {'4_Residual_x':'4-Residual_x','4_Residual_y':'4-Residual_y'})\n",
    "a = a[['t','FCAPf','FCA','MonthlyFCAPf', 'MonthlyFCA','WeeklyFCAPf',\n",
    "                    'WeeklyFCA','FCAP*', 'FCA*', 'WeeklyFCAP*', 'WeeklyFCA*', \n",
    "                    'MonthlyFCAP*','MonthlyFCA*','Holder_act','sBgroup','id',\n",
    "       'BGId_x','BGId_y','id_x','id_y','date']]\n",
    "gg = a.groupby('id')\n",
    "del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(60,100)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round  61\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  62\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  63\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  64\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  65\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  66\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  67\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  68\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  69\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  70\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  71\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  72\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  73\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  74\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  75\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  76\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  77\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  78\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  79\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  80\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  81\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  82\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  83\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  84\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  85\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  86\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  87\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  88\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  89\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  90\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  91\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  92\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  93\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  94\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  95\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  96\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  97\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  98\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  99\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n",
      "Round  100\n",
      "Start\n",
      "End6\n",
      "RBGMonthly done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for morteza in range(60,100):\n",
    "    \n",
    "    print( \"Round \" , morteza+1)\n",
    "    print(\"Start\")\n",
    "    Rdata = pd.DataFrame()\n",
    "    Rdata = gg.apply(RPair ,GData = BG, Pairs = Pairs,dgg = dgg , timeId = timeId).reset_index().drop(columns = ['level_1'] )\n",
    "\n",
    "\n",
    "    print(\"End\")\n",
    "    \n",
    "    dt = Rdata.drop_duplicates(['nId','t_Month'],keep = \"last\")\n",
    "    del Rdata\n",
    "    dt = dt[~dt.nId.isnull()]\n",
    "    dt = dt.sort_values(by = ['id']).reset_index(drop = True)\n",
    "    \n",
    "    Holders = list(set(dt.nId))\n",
    "    ids = list(range(len(Holders)))\n",
    "    mapingdict = dict(zip(Holders, ids))\n",
    "    dt['MergeId'] = dt['nId'].map(mapingdict)\n",
    "    dt = dt.drop_duplicates(['MergeId','t_Month'])\n",
    "    \n",
    "    n3 =  path + 'RBGMonthlyNormalzedFCAP6.1' + \"-Sample\" + str(morteza+1)+  \".parquet\"\n",
    "    dt.to_parquet(n3)\n",
    "    \n",
    "    print(\"RBGMonthly done\")\n",
    "    del dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
